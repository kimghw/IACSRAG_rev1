# 문서 검색 플랫폼(RAG) - 프로젝트 상세 설계서 (v2.0)

## 목차
1. [전체 시스템 아키텍처](#1-전체-시스템-아키텍처)
2. [인터페이스 설계](#2-인터페이스-설계)
3. [데이터 모델 설계](#3-데이터-모델-설계)
4. [라이브러리 및 기술 스택](#4-라이브러리-및-기술-스택)
5. [모듈별 상세 설계](#5-모듈별-상세-설계)
6. [보안 및 성능 고려사항](#6-보안-및-성능-고려사항)
7. [디자인 패턴 적용](#7-디자인-패턴-적용)
8. [개발 표준 및 규칙](#8-개발-표준-및-규칙)

## 1. 전체 시스템 아키텍처

### 1.1 아키텍처 원칙

#### 1.1.1 핵심 원칙
- **이벤트 기반 아키텍처**: 모듈 간 느슨한 결합과 확장성 확보
- **도메인 주도 설계(DDD)**: 비즈니스 도메인 중심의 모듈 구성
- **12 Factor App**: 클라우드 네이티브 애플리케이션 원칙 준수
- **마이크로서비스 준비**: 향후 서비스 분리를 고려한 모듈 설계

#### 1.1.2 기술 결정 기록 (ADR)
```yaml
ADR-001:
  제목: 이벤트 기반 아키텍처 채택
  상태: 승인됨
  결정: Kafka를 이용한 이벤트 기반 통신
  이유: 
    - 모듈 간 결합도 감소
    - 비동기 처리로 성능 향상
    - 장애 전파 방지

ADR-002:
  제목: 벡터 DB로 Qdrant 선택
  상태: 승인됨
  결정: Qdrant를 벡터 저장소로 사용
  이유:
    - 우수한 필터링 기능
    - 메타데이터 검색 지원
    - 활발한 커뮤니티
```

### 1.2 시스템 구조
```
┌─────────────────────────────────────────────────────────────────┐
│                      FastAPI Application                         │
│                    (단일 애플리케이션)                            │
└────────┬──────────┬──────────┬──────────┬──────────────────────┘
         │          │          │          │
    ┌────▼────┐ ┌──▼────┐ ┌──▼────┐ ┌──▼────┐
    │ Ingest  │ │Process│ │Search │ │Monitor│
    │ Module  │ │Module │ │Module │ │Module │
    └────┬────┘ └──┬────┘ └──┬────┘ └──┬────┘
         │         │         │         │
    ┌────▼─────────▼─────────▼─────────▼────┐
    │           Kafka Event Bus              │
    │      (이벤트 기반 비동기 통신)           │
    └────────────────────────────────────────┘
                    │
    ┌───────────────▼────────────────────────┐
    │         Storage Layer                  │
    ├─────────────┬──────────────────────────┤
    │  MongoDB    │   Local File System      │
    │ (Metadata)  │   (임시 파일 저장)        │
    └─────────────┴──────────────────────────┘
                    │
    ┌───────────────▼────────────────────────┐
    │       Vector Database                  │
    │          (Qdrant)                      │
    └────────────────────────────────────────┘
```

### 1.3 모듈별 책임 정의

#### 1.3.1 Ingest Module (문서 수집)
- **책임**: PDF/웹 문서 수집, Json, 메타데이터 관리
- **기술**: FastAPI, MongoDB, 로컬 파일 시스템, Kafka
- **엔드포인트**: /api/v1/documents/*
- **주요 컴포넌트**:
  - DocumentService: 문서 관리 서비스
  - DocumentRepository: 문서 메타데이터 저장소
  - FileHandler: 파일 처리 및 저장
  - 컴스텀 json 로더 : json 을 받아서 일부 키는 임베딩 벡터로, 일부는 태그로 변환하여 db에 저장

#### 1.3.2 Process Module (문서 처리)
- **책임**: 텍스트 추출, 청킹, 임베딩 생성, 중복 제거
- **기술**: LangChain, openai-embedding, Kafka, Worker Pool
- **백그라운드 작업**: Kafka Consumer 기반 비동기 처리
- **주요 컴포넌트**:
  - TextExtractor: 다양한 문서 형식에서 텍스트 추출
  - TextChunker: 텍스트를 의미 있는 청크로 분할
     -- 짧은 텍스트(Json, Email 등) : LangChain-SemanticChunker
     -- 규정/지침 : Docling – `hybrid_chunking
     -- 메뉴얼 : LlamaIndex – `SemanticSplitter`
     -- (향후) GPU A6000*2 :SentenceTransformers
  - EmbeddingService: 텍스트 임베딩 생성
  - ChunkRepository: 청크 저장 및 관리

#### 1.3.3 Search Module (검색/답변)
- **책임**: 벡터 검색, RAG 파이프라인, 답변 생성
- **기술**: Qdrant, OpenAI API
- **엔드포인트**: /api/v1/search/*
- **주요 컴포넌트**:
  - SearchService: 검색 및 답변 생성 서비스
  - VectorDBClient: 벡터 데이터베이스 연동
  - LLMService: 대규모 언어 모델 연동
    -- API KEY : OpenAI

#### 1.3.4 Monitor Module (모니터링)
- **책임**: 기본 메트릭 수집, 로깅
- **기술**: Python logging, 간단한 통계 수집
- **엔드포인트**: /api/v1/stats/*

### 1.4 이벤트 흐름 및 비동기 처리

#### 1.4.1 Ingest Module 이벤트 흐름
```
┌───────────────┐     ┌───────────────┐     ┌───────────────┐
│  API 요청     │     │ 문서 저장 및   │     │ Kafka 이벤트  │
│ (파일 업로드) │────▶│ 메타데이터 생성│────▶│   발행       │
└───────────────┘     └───────────────┘     └───────┬───────┘
                                                    │
                                                    ▼
┌───────────────┐     ┌───────────────┐     ┌───────────────┐
│ 처리 상태     │     │ Process Module│     │ Kafka Consumer│
│ 업데이트      │◀────│ (텍스트 추출) │◀────│ (이벤트 구독) │
└───────────────┘     └───────────────┘     └───────────────┘
```

1. **문서 업로드 API 호출**: 클라이언트가 `/api/v1/documents/upload` 엔드포인트로 파일 업로드
2. **메타데이터 생성 및 저장**: 
   - 파일 저장 (FileHandler)
   - 문서 메타데이터 생성 및 저장 (DocumentRepository)
   - 문서 상태를 "ingested"로 설정
3. **이벤트 발행**: 
   - `document.ingested` 이벤트를 Kafka에 발행
   - 이벤트 페이로드에 document_id, 파일 경로, 메타데이터 포함
4. **이벤트 구독 및 처리**:
   - Process Module의 Kafka Consumer가 `document.ingested` 이벤트 구독
   - 이벤트 수신 시 텍스트 추출 작업 큐에 추가
5. **상태 업데이트**:
   - 처리 시작 시 문서 상태를 "processing"으로 업데이트
   - 처리 완료 시 "completed" 또는 실패 시 "failed"로 업데이트

#### 1.4.2 Process 단계 병렬 처리 전략

```
┌───────────────┐     ┌───────────────┐     ┌───────────────┐
│ Kafka Consumer│     │ Worker Pool   │     │ 텍스트 추출   │
│ (이벤트 구독) │────▶│ (ProcessPool) │────▶│ (병렬 처리)   │
└───────────────┘     └───────────────┘     └───────┬───────┘
                                                    │
                                                    ▼
┌───────────────┐     ┌───────────────┐     ┌───────────────┐
│ 임베딩 생성   │     │ Worker Pool   │     │ 청킹 처리     │
│ (GPU 활용)    │◀────│ (ThreadPool)  │◀────│ (병렬 처리)   │
└───────┬───────┘     └───────────────┘     └───────────────┘
        │
        ▼
┌───────────────┐     ┌───────────────┐
│ 벡터 저장     │     │ 이벤트 발행   │
│ (Qdrant)      │────▶│ (완료 알림)   │
└───────────────┘     └───────────────┘
```

**병렬 처리 전략**:

1. **Worker Pool 구성**:
   - CPU 바운드 작업(텍스트 추출, 청킹): `concurrent.futures.ProcessPoolExecutor`
   - I/O 바운드 작업(DB 저장, API 호출): `concurrent.futures.ThreadPoolExecutor`
   - 워커 수: CPU 코어 수 * 2 (기본값)

2. **자원 할당**:
   - 텍스트 추출: 최대 CPU 코어의 75%
   - 임베딩 생성: GPU 메모리의 80% (GPU 사용 가능 시)
   - 벡터 저장: 최대 동시 연결 수 제한 (Qdrant 설정에 따름)

3. **배치 처리**:
   - 청크 배치 크기: 32개 (기본값)
   - 임베딩 배치 크기: 16개 (기본값)
   - 벡터 저장 배치 크기: 100개 (기본값)

4. **백프레셔 처리**:
   - 작업 큐 최대 크기: 1000
   - 큐 포화 시 새 작업 거부 (재시도 로직 포함)
   - 처리 속도 모니터링 및 자동 스케일링

## 2. 인터페이스 설계

### 2.1 REST API 명세

#### 2.1.1 문서 수집 API

```yaml
POST /api/v1/documents/upload
  Headers:
    Authorization: Bearer {token}
  Request:
    file: binary (multipart/form-data)
    metadata: object (optional)
  Response:
    document_id: string
    status: string
    processing_url: string

POST /api/v1/documents/email
  Request:
    email_content: string
    attachments: array[object]
  Response:
    document_ids: array[string]

POST /api/v1/documents/web
  Request:
    url: string
    scraping_config: object
  Response:
    document_id: string
    status: string
```

#### 2.1.2 검색 API
```yaml
POST /api/v1/search
  Headers:
    Authorization: Bearer {token}
  Request:
    query: string
    top_k: int (default: 10)
    filters: object (optional)
  Response:
    results: array[
      document_id: string
      chunk_text: string
      score: float
      metadata: object
    ]

POST /api/v1/search/answer
  Headers:
    Authorization: Bearer {token}
  Request:
    query: string
    context_documents: array[string] (optional)
    model: string (default: "gpt-3.5-turbo")
  Response:
    answer: string
    sources: array[object]
    confidence: float
```

### 2.2 이벤트 스키마

#### 2.2.1 Document Events
```json
{
  "event_id": "550e8400-e29b-41d4-a716-446655440000",
  "event_type": "document.ingested",
  "timestamp": "2025-01-30T14:00:00Z",
  "payload": {
    "document_id": "doc-123",
    "source_type": "pdf",
    "file_path": "s3://documents/doc-123.pdf",
    "metadata": {
      "size": 1048576,
      "pages": 10,
      "user_id": "user-456"
    }
  },
  "context": {
    "correlation_id": "corr-789",
    "user_id": "user-456"
  }
}
```

#### 2.2.2 Processing Events
```json
{
  "event_type": "text.extracted",
  "payload": {
    "document_id": "doc-123",
    "chunks": [
      {
        "chunk_id": "chunk-001",
        "text": "...",
        "metadata": {
          "page": 1,
          "position": 0
        }
      }
    ],
    "total_chunks": 25
  }
}
```

### 2.3 Chunk 사이즈 관리 전략

#### 2.3.1 청킹 기준 및 권장 사이즈

| 문서 유형 | 청킹 기준 | 기본 청크 사이즈 | 최대 청크 사이즈 | 오버랩 |
|----------|----------|----------------|----------------|--------|
| PDF      | 페이지 + 문단 | 512 토큰      | 800 토큰        | 50 토큰 |
| DOCX     | 문단      | 512 토큰        | 800 토큰        | 50 토큰 |
| TXT      | 문단      | 512 토큰        | 800 토큰        | 50 토큰 |
| HTML     | 태그 기반  | 512 토큰        | 800 토큰        | 50 토큰 |
| 이메일    | 문단      | 512 토큰        | 800 토큰        | 50 토큰 |

**청킹 전략**:

1. **문서 유형별 청킹**:
   - PDF: 페이지 경계 우선, 페이지 내에서 문단 분할
   - DOCX: 문단 및 헤딩 기준 분할
   - HTML: 의미 있는 태그(`<p>`, `<div>`, `<section>` 등) 기준 분할

2. **청크 품질 관리**:
   - 최소 청크 길이: 100 토큰 (너무 짧은 청크는 병합)
   - 최대 청크 길이: 800 토큰 (너무 긴 청크는 분할)
   - 문장 경계 보존: 가능한 문장 중간에서 분할하지 않음

3. **특수 처리**:
   - 표/차트: 별도 청크로 처리하고 메타데이터에 표시
   - 코드 블록: 가능한 분할하지 않고 단일 청크로 유지
   - 목록(리스트): 관련 항목은 함께 유지

4. **메타데이터 강화**:
   - 각 청크에 원본 위치 정보 추가 (페이지, 문단, 위치)
   - 청크 간 관계 정보 추가 (이전/다음 청크 ID)
   - 섹션/헤딩 정보 추가 (가능한 경우)

## 3. 데이터 모델 설계

### 3.1 MongoDB 스키마

#### 3.1.1 Users Collection
```javascript
{
  "_id": ObjectId,
  "email": String,
  "password_hash": String,
  "roles": ["user", "admin"],
  "created_at": ISODate,
  "updated_at": ISODate,
  "settings": {
    "default_model": String,
    "max_results": Number
  }
}
```

#### 3.1.2 Documents Collection
```javascript
{
  "_id": String, // document_id
  "user_id": String,
  "source_type": String, // "email", "pdf", "web"
  "status": String, // "ingested", "processing", "completed", "failed"
  "file_path": String, // MinIO/S3 path
  "metadata": {
    "title": String,
    "size": Number,
    "mime_type": String,
    "pages": Number,
    "language": String
  },
  "processing_stats": {
    "chunks_count": Number,
    "embeddings_count": Number,
    "processing_time_ms": Number
  },
  "created_at": ISODate,
  "updated_at": ISODate
}
```

#### 3.1.3 Chunks Collection
```javascript
{
  "_id": String, // chunk_id
  "document_id": String,
  "chunk_index": Number,
  "text": String,
  "text_hash": String, // SHA-256 for deduplication
  "metadata": {
    "page": Number,
    "section": String,
    "char_start": Number,
    "char_end": Number,
    "token_count": Number,
    "prev_chunk_id": String,
    "next_chunk_id": String
  },
  "embedding_id": String, // Reference to vector DB
  "created_at": ISODate
}
```

### 3.2 Vector Database Schema (Qdrant)

```python
from qdrant_client import QdrantClient
from qdrant_client.http import models

# Collection: document_embeddings
client = QdrantClient("localhost", port=6333)

# Create collection
client.create_collection(
    collection_name="document_embeddings",
    vectors_config=models.VectorParams(
        size=768,  # all-MiniLM-L6-v2 차원
        distance=models.Distance.COSINE
    )
)

# 필드 스키마 정의
client.create_payload_index(
    collection_name="document_embeddings",
    field_name="document_id",
    field_schema=models.PayloadSchemaType.KEYWORD
)

client.create_payload_index(
    collection_name="document_embeddings",
    field_name="chunk_id",
    field_schema=models.PayloadSchemaType.KEYWORD
)

client.create_payload_index(
    collection_name="document_embeddings",
    field_name="user_id",
    field_schema=models.PayloadSchemaType.KEYWORD
)

# 벡터 삽입 예시
client.upsert(
    collection_name="document_embeddings",
    points=[
        models.PointStruct(
            id="embedding_id_1",
            vector=[0.1, 0.2, ...],
            payload={
                "document_id": "doc_123",
                "chunk_id": "chunk_001",
                "user_id": "user_456",
                "metadata": {
                    "page": 1,
                    "section": "Introduction"
                }
            }
        )
    ]
)
```

### 3.3 로컬 캐시 구조 (프로토타입)

```yaml
# 메모리 캐시 (Python dict)
# 검색 결과 캐시
search_cache:
  key: query_hash
  value:
    - results: array
    - timestamp
  TTL: 1 hour

# 문서 처리 상태
processing_status:
  key: document_id
  value:
    - status
    - progress
    - error_message
```

## 4. 라이브러리 및 기술 스택

### 4.1 핵심 라이브러리

#### 4.1.1 백엔드 프레임워크
```toml
[dependencies]
# Web Framework
fastapi = "^0.109.0"
uvicorn = {extras = ["standard"], version = "^0.27.0"}
pydantic = "^2.5.0"
pydantic-settings = "^2.1.0"

# Async Support
asyncio = "*"
aiohttp = "^3.9.0"
httpx = "^0.26.0"

# Database Drivers
motor = "^3.3.2"  # MongoDB async driver
qdrant-client = "^1.7.0"  # Qdrant client

# Message Queue
aiokafka = "^0.8.1"  # Kafka async client

# Concurrency
concurrent-futures-pool = "^0.2.0"

# AI/ML
langchain = "^0.1.0"
sentence-transformers = "^2.2.2"
openai = "^1.10.0"
tiktoken = "^0.5.0"

# Document Processing
pypdf = "^3.17.0"
python-docx = "^1.1.0"
beautifulsoup4 = "^4.12.0"
python-magic = "^0.4.27"

# File Upload
python-multipart = "^0.0.6"

# Logging
structlog = "^24.1.0"

# Development
pytest = "^7.4.0"
pytest-asyncio = "^0.23.0"
ruff = "^0.1.0"
mypy = "^1.8.0"
pre-commit = "^3.6.0"
```

### 4.2 외부 서비스 (프로토타입)

```yaml
Infrastructure:
  - MongoDB 7.0: 메타데이터 저장
  - Qdrant: 벡터 데이터베이스
  - Kafka: 이벤트 메시징
  - 로컬 파일 시스템: 임시 파일 저장

AI Services:
  - OpenAI API: GPT 모델 (답변 생성)
  - Hugging Face: 임베딩 모델 (all-MiniLM-L6-v2)
```

## 5. 모듈별 상세 설계

### 5.1 프로토타입 프로젝트 구조

```
rag-prototype/
├── src/
│   ├── api/
│   │   └── v1/
│   │       ├── documents.py  # 문서 업로드 API
│   │       ├── search.py     # 검색 API
│   │       └── stats.py      # 통계 API
│   ├── core/
│   │   ├── config.py        # 설정
│   │   ├── exceptions.py    # 예외 정의
│   │   └── events.py        # 이벤트 정의
│   ├── modules/
│   │   ├── ingest/
│   │   │   ├── domain/
│   │   │   │   ├── entities.py
│   │   │   │   └── value_objects.py
│   │   │   ├── application/
│   │   │   │   ├── use_cases/
│   │   │   │   │   └── parse_email.py
│   │   │   │   └── services/
│   │   │   │       └── document_service.py
│   │   │   └── infrastructure/
│   │   │       ├── repositories/
│   │   │       │   └── document_repository.py
│   │   │       └── file_handler.py
│   │   ├── process/
│   │   │   ├── domain/
│   │   │   │   └── entities.py
│   │   │   ├── application/
│   │   │   │   ├── use_cases/
│   │   │   │   │   ├── extract_text.py
│   │   │   │   │   ├── create_chunks.py
│   │   │   │   │   ├── generate_embeddings.py
│   │   │   │   │   └── deduplicate_chunks.py
│   │   │   │   └── services/
│   │   │   │       └── document_processor.py
│   │   │   └── infrastructure/
│   │   │       ├── text_extractor.py
│   │   │       ├── text_chunker.py
│   │   │       └── embedding_service.py
│   │   └── search/
│   │       ├── domain/
│   │       │   └── entities.py
│   │       ├── application/
│   │       │   ├── use_cases/
│   │       │   │   └── generate_answer.py
│   │       │   ├── ports/
│   │       │   │   └── llm_port.py
│   │       │   └── services/
│   │       │       └── search_service.py
│   │       └── infrastructure/
│   │           ├── adapters/
│   │           │   └── openai_adapter.py
│   │           ├── vector_db.py
│   │           └── llm_service.py
│   ├── infrastructure/
│   │   ├── database/
│   │   │   └── mongodb.py
│   │   ├── vectordb/
│   │   │   └── qdrant_client.py
│   │   └── messaging/
│   │       └── kafka_client.py
│   └── main.py
├── tests/
├── data/           # 로컬 파일 저장
├── logs/           # 로그 파일
└── pyproject.toml
```

### 5.2 주요 컴포넌트 구현

#### 5.2.1 Ingest Module 컴포넌트

**DocumentRepository**:
```python
class DocumentRepository:
    """문서 저장소"""
    
    def __init__(self, db: AsyncIOMotorDatabase):
        self.db = db
        self.collection = db.documents
    
    async def save(self, document: Document) -> str:
        """문서 저장"""
        # 구현 내용
        pass
    
    async def find_by_id(self, document_id: str) -> Optional[Document]:
        """ID로 문서 조회"""
        # 구현 내용
        pass
    
    async def update_status(self, document_id: str, status: str) -> bool:
        """문서 상태 업데이트"""
        # 구현 내용
        pass
    
    async def find_by_status(self, status: str, limit: int, skip: int) -> List[Document]:
        """상태별 문서 조회"""
        # 구현 내용
        pass
```

**FileHandler**:
```python
class FileHandler:
    """파일 처리기"""
    
    @classmethod
    async def save_upload_file(cls, file: UploadFile, document_id: str) -> Tuple[str, Dict[str, Any]]:
        """업로드된 파일 저장"""
        # 구현 내용
        pass
    
    @classmethod
    async def delete_document_files(cls, document_id: str) -> bool:
        """문서 파일 삭제"""
        # 구현 내용
        pass
```

**EventPublisher**:
```python
class EventPublisher:
    """이벤트 발행자"""
    
    def __init__(self, topic: str = "document_events"):
        self.topic = topic
    
    async def publish(self, event_type: str, payload: Dict[str, Any], 
                     context: Optional[Dict[str, Any]] = None) -> bool:
        """이벤트 발행"""
        # 구현 내용
        pass
    
    async def publish_document_ingested(self, document_id: str, source_type: str, 
                                       file_path: str, metadata: Dict[str, Any], 
                                       user_id: Optional[str] = None) -> bool:
        """문서 수집 이
