다음은 제공해주신 유즈케이스 명세서(v1.2)를 정리한 내용입니다.
문서 검색 플랫폼(RAG) – 유즈케이스 명세서 (v1.2)
개요
이 문서 검색 플랫폼은 다양한 출처(이메일, PDF 업로드, JSON/웹 스크랩)로부터 문서를 수집합니다. 수집된 문서에서 텍스트를 추출한 뒤, 의미 단위(청크)로 분할합니다. 이후 각 청크는 벡터로 변환(임베딩)되어 Vector DB에 저장됩니다. 사용자는 자연어 형태로 검색 질의를 입력하여 Vector DB를 통해 유사도 검색을 수행하고, 검색된 문서를 기반으로 답변을 생성할 수 있습니다. 또한, 모니터링을 위한 메트릭도 수집합니다.
전체 흐름

이메일(UC-01), PDF(UC-02), 웹/JSON(UC-03) 문서를 수집합니다.
텍스트를 추출(UC-04)하고 의미 단위로 청크를 생성합니다(UC-05).
청크를 임베딩 벡터로 변환(UC-06)하고 저장(UC-07)한 뒤 중복을 제거합니다(UC-08).
검색을 수행(UC-09)하고 LLM을 활용해 답변을 생성합니다(UC-10).
메트릭 모니터링을 수행합니다(UC-11).
각 유즈케이스는 '아토믹' 단위로 정의되어 있으며, 이를 조합하여 이메일 문서 수집, PDF 업로드 수집, JSON/웹 수집, 자연어 검색 등 ‘컴포짓’ 형태로 활용됩니다.

아토믹 유즈케이스 상세
(1) UC‑01 이메일 파싱

이메일 Collector는 큐 메시지(또는 Webhook)를 통해 수신된 이메일의 본문과 첨부 파일을 추출합니다.
추출 후, 원본을 로컬 DB나 오브젝트 스토리지 등에 저장합니다.
후속 텍스트 추출 과정을 위해 문서 메타데이터(ingest 요청)를 등록합니다.
(2) UC‑02 PDF 업로드

인증된 사용자가 PDF를 업로드하면, 서버는 이를 파일 저장소에 저장합니다.
메타정보(해시, 상태 등)를 DB에 기록한 뒤, ingestion 큐에 등록합니다.
파일 용량 제한(예: 100MB)을 초과하는 경우 업로드를 거부합니다.
sync 모드 요청 시, 내부 파이프라인(텍스트 추출~중복 제거) 완료 후 최종 상태를 반환할 수 있습니다.
업로드 중 네트워크 오류 발생 시 2-Phase Commit 또는 3회 재시도를 진행하고, 실패 시 DLQ로 처리합니다.
(3) UC‑03 JSON/웹 스크랩 수집

CRON 또는 웹훅으로 트리거되는 ETL 스케줄러가 외부 JSON API나 웹 페이지(HTML)로부터 데이터를 가져옵니다.
수신된 JSON/HTML을 원본 그대로 저장 후, 로컬 DB에 문서 수집 상태를 기록합니다.
HTTP 오류(4xx/5xx) 발생 시 지수 백오프를 통해 재시도하고, 재시도 한도를 초과하면 DLQ로 분류합니다.
(4) UC‑04 텍스트 추출

PDF나 HTML 등 바이너리·마크업 포맷에서 UTF‑8 텍스트를 추출합니다.
Apache Tika, PyPDF 등 라이브러리를 활용하여 텍스트를 분리합니다.
텍스트 추출이 끝나면 ‘TextExtracted’ 이벤트를 발행합니다.
(5) UC‑05 의미 기반 청크

텍스트를 일정 기준(문단, 헤더, 빈줄 등 휴리스틱)으로 분할하여, 200~400 토큰 정도의 청크 단위로 만듭니다.
지나치게 짧은 조각은 병합하고, 최종적으로 512 토큰을 넘지 않도록 조정합니다.
분할된 청크는 JSON 형태로 보관하거나 후속 임베딩을 위해 큐에 넘깁니다.
청크가 너무 많은 경우(예: 1만 개 이상) oversize 플래그를 설정하고 관리자가 추후 확인할 수 있도록 상태를 남깁니다.
(6) UC‑06 임베딩 생성

청크 단위 텍스트를 벡터로 변환하기 위해 임베딩 모델(OpenAI/Hugging Face 등)을 호출합니다.
일반적으로 32개 단위 배치로 모델 API를 호출해 임베딩을 얻고, 청크와 임베딩 벡터를 매핑합니다.
처리 결과가 준비되면 ‘EmbeddingsReady’ 이벤트를 발행합니다.
(7) UC‑07 임베딩 저장

생성된 벡터들을 Vector DB(Qdrant 등)에 Upsert 형태로 저장합니다.
org_id나 프로젝트 ID 등에 따라 샤딩을 적용해 확장성을 높입니다.
저장 과정에서 오류가 지속 발생하면 DLQ로 분류합니다.
(8) UC‑08 중복 제거

청크 텍스트의 해시(SHA‑256)로 중복 여부를 판단하여, 이미 동일한 청크가 존재하면 새로 저장하지 않습니다.
완전 동일 문서만 중복 처리하며, 부분 일치나 유사도 중복은 별도의 로직이 필요할 수 있습니다.
해시 충돌 가능성은 작지만, 만약 충돌이 의심되면 실제 텍스트 비교를 수행할 수 있도록 설계합니다.
(9) UC‑09 벡터 검색

사용자가 자연어 질의를 입력하면, 이를 임베딩 벡터로 변환한 뒤 Vector DB에서 k‑NN 검색을 수행합니다.
상위 K개 결과를 가져오며, 필요 시 Re-ranker 모델을 적용해 랭킹을 조정할 수 있습니다.
(10) UC‑10 답변 생성

검색된 문서를 기반으로 LLM에게 프롬프트를 보내어 답변을 생성합니다.
K개의 문서 요약 혹은 재가공을 프롬프트에 반영해, 연관된 근거와 함께 답변을 받습니다.
LLM이 응답을 반환하면, 이를 UI에 표시하고 로그나 메트릭에 기록합니다.
만약 LLM이 응답에 실패하면 간단한 ‘추출형 답변’ 방식으로 대체할 수도 있습니다.
(11) UC‑11 메트릭 모니터링

전체 파이프라인에서 처리된 문서 수, 처리 속도, 검색 시간, 오류 발생 건수 등을 수집하여 시각화합니다.
컴포짓 유즈케이스 개요
이메일 문서 수집(CUC‑01): UC‑01을 통해 이메일에서 파일/본문을 추출한 뒤, UC‑04~UC‑08까지 일련의 과정을 수행합니다.
PDF 업로드 수집(CUC‑02): UC‑02에서 사용자가 파일을 업로드하고, 이어서 UC‑04~UC‑08까지 진행합니다.
JSON/웹 수집(CUC‑03): UC‑03을 통해 받은 외부 데이터를 텍스트 추출(UC‑04) 후 청크/임베딩/저장/중복 제거 순으로 처리합니다.
자연어 검색(CUC‑04): UC‑09와 UC‑10을 조합해 검색 및 답변을 생성합니다.
관리자 대시보드 운영(CUC‑05): UC‑11(메트릭 모니터링)을 통해 각종 KPI를 확인하고 대시보드로 관리합니다.
가정 & 결정 사항
이메일, PDF, 웹/JSON 등 다양한 형태의 입력을 하나의 공통 흐름(추출 → 청크화 → 임베딩 → 저장)으로 처리합니다.
작업자(Worker)가 문서를 처리할 수 있도록 설계하며, 필요하면 수평 확장을 통해 처리량을 늘립니다.
오류 코드는 E1xx(클라이언트), E2xx(수집), E3xx(Vector DB), E4xx(LLM) 네 범주로 나누어 로깅·대처합니다.
위와 같은 구조를 통해 문서 수집과 임베딩 기반 검색 기능을 안정적으로 제공하며, 추후 다양한 문서 형식이나 언어로 확장하기도 용이하도록 설계합니다.
참고: 이 명세서는 기존 v1.2 초안을 기반으로 OCR 처리·오류 알림·접근제어(UC-12, UC-13)·Rate Limit 관련 언급 등을 제외하고 표 대신 글로만 구성된 예시입니다.

